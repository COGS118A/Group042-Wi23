{
	"cells": [{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# COGS 118A - Project Checkpoint"
			]
		},
		{
				"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Names\n",
				"\n",
				"- Masiah Manzano\n",
				"- Jesus Enrique Mendez\n",
				"- Armaan Johal\n",
				"- \n",
				"- "
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Abstract \n",
				"The goal that we want to solve is to help the world find an answer to whatever it is that they are asking for. We thought back to how when we were young, we could ask a magic 8 ball anything and receive an answer, but what if we can somehow manipulate this so that the magic 8 ball can be more like how CHAT GPT is for everyone nowadays. Where the user will ask a question they feel they need an answer to that is not necessarily academic, and unlike CHAT GPT, it can be about anything with no restrictions and still receive an answer.The data we will be utilizing is yet to be determined but we plan on taking a public poll from our peers on what questions they would really want answered and it can be about anything. Lastly, success will be measured when an adequate answer can be given that means satisfactory for the one who is asking for magic 8 ball. The data used throughout this project represents what the user will be inputting in the format of a question and it will be measured through various responses that are placed into the code to give the user a variety of different answers for what they are asking. Lastly, performance will be measured if the answers given back actually make sense for what is asked, if it is too random then this will be measured as a failure since our goal here is to give back the user a answer they can be happy with. \n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Background\n",
				"\n",
				"What helped us come up with this idea is finding ways to make a lot of input data be used and give back an output. This is important because as we researched online, we found that many machine learning algorithms receive a lot of data and because of this cannot scale as good as it needs to. A good example of this is when algorithms use K-means. A paper we found (https://dl.acm.org/doi/10.1145/2347583.2347596) discusses how K-means is a learning algorithm that implements this and as the data contains to increase, the time it takes to output is excessive. So what if we can use the 8 ball simulator as a way to limit down response times even if the data is huge (this general problem is still likely to change but this is the best we could come up with to make sure we can still use this idea as a ML-learning solution for a ML problem). Another reference that dives deeper into scalability comes from (https://livebook.manning.com/book/real-world-machine-learning/chapter-9/1) Here we see how scalability has been a constant issue for many years now for algorithms and we are trying to find ways to use our idea to combat against this or to showcase how we can better the workload while still using a lot of data sets"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Problem Statement\n",
				"\n",
				"Given the feedback we received, we decided to take a different approach on how we plan to use what we came up with. We still want to use our 8 ball simulator but in a way that can help answer a ML-potential question and while researching certain ways to better this problem, we have come to the conclusion that we should take an approach of either scalability, or to help combat biased algorithms and systems. We believe that our current 8 ball simulator can either focus primarily on both or one of these because, if we take the approach to help scalability since most models become difficult as data is increased, we want to showcase that this is not always the case because we want to be able to generate as many answers as we possibly can and still be able to give an output. Again, this is still a work in progress but the general area we want to focus on is scalability and how we can use this simulation as an example for other models who suffer from too much data, which this can be used as an example how they can better their models to take up a lot of data and still work good."
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Data\n",
				"\n",
				"- Since it would take a really long time we decided it is best to not interview others (as fun as it may be) and instead just search on our own time commonly asked questions and gather information all in just one sitting and apply this to our code. We decided to research on some common questions asked by people and we figured the best way to do this is by asking questions that truly get to know someone so we stumbled upon these 100 questions and here is the link https://www.signupgenius.com/groups/getting-to-know-you-questions.cfm. We primarily used this as a reference for the type of questions we want to ask and for what to expect to receive if these types of questions are asked. Another example that we took a look at to help combat scalability issues with our code and to help better other algorithms using this idea of an 8 ball simulator, we took a look at Ray. Ray is a software program that takes heavy workloads of code and makes it really easy to scale the workload. We are going to continue looking at how this program seems to help other algorithms and see if we can apply this or any of the methods used to better our general idea on how to tackle a ML-problem \n",
				"- At the end of this journey we still did not reach the amount of variables we wanted. This is mostly due to the lack of having a full team that others luckily did have\n",
				"- Our observations consist of finding more ways for us to implement methods of greater responses. What we mean by this is that we want to be able to answer questions without a one word answer. We want the user to actually feel as if they are having a conversation with our code\n",
				"- In the end we made sure our code looks clean and did so by making sure that a simple question can receive an answer. We have removed a lot of unnecessary code that just made what we had look like a lot. We stuck to what just seems to work and now we are currently findings ways to make our output go from seeming like it is a random answer to actually being an answer which makes sense \n"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Proposed Solution\n",
				"\n",
				"Our proposed solution to make sure that the user will get an answer which makes sense by implementing code that notices what the user is asking to give back a specific answer. We currently decided to use if statements. So, if our user starts off by asking a 'can' question it would give back a certain reply. This is how we plan to make sure this project can get interesting. While it may seem basic to be working this, it is so fun to do this. We know that classes can be serious at times but with this project and the liberty we have to do what we want with this is just so awesome and we truly are having a great time working on this. We hope our final product can help others see that this is something cool and can be played around with. But when focusing on how to better this proposed problem of scalability, we so far have come up with data parallelism when working on the code we have so far. What we mean by this is making the data we have into small subsets which then process them. Not only is this a way to clean up our data and make it look nice, but can be a start to combat against scalability issues among algorithms. Another way to combat against this proposed problem is actually to not just use the if statements but instead use dictionary to store possible outcomes for our simulator. We are still expanding these general idea to better improve our idea to create a better ML-solution."
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Evaluation Metrics\n",
				"\n",
				"One evaluation metric to be sure our code is working as it should is to definitely place in a numerous amount of questions that are structured in the way to make sure our if statements throughout the code are working properly. After brainstorming more on how we can make this idea more of a ML based one, we decided to implement Recall. We can use recall to interpret a positive sample of a user asking a question that can be answered and if identified it would give back an accurate response. We will add a set of labeled data to train the model to predict whether a question can be answered by the 8 ball, or if it cannot. We plan on further expanding on this idea of course and this is just a general idea we came up with as a team."
			]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "You may have done tons of work on this. Not all of it belongs here. \n",
    "\n",
    "Reports should have a __narrative__. Once you've looked through all your results over the quarter, decide on one main point and 2-4 secondary points you want us to understand. Include the detailed code and analysis results of those points only; you should spend more time/code/plots on your main point than the others.\n",
    "\n",
    "If you went down any blind alleys that you later decided to not pursue, please don't abuse the TAs time by throwing in 81 lines of code and 4 plots related to something you actually abandoned.  Consider deleting things that are not important to your narrative.  If its slightly relevant to the narrative or you just want us to know you tried something, you could keep it in by summarizing the result in this report in a sentence or two, moving the actual analysis to another file in your repo, and providing us a link to that file.\n",
    "\n",
    "### Subsection 1\n",
    "\n",
    "You will likely have different subsections as you go through your report. For instance you might start with an analysis of the dataset/problem and from there you might be able to draw out the kinds of algorithms that are / aren't appropriate to tackle the solution.  Or something else completely if this isn't the way your project works.\n",
    "\n",
    "### Subsection 2\n",
    "\n",
    "Another likely section is if you are doing any feature selection through cross-validation or hand-design/validation of features/transformations of the data\n",
    "\n",
    "### Subsection 3\n",
    "\n",
    "Probably you need to describe the base model and demonstrate its performance.  Maybe you include a learning curve to show whether you have enough data to do train/validate/test split or have to go to k-folds or LOOCV or ???\n",
    "\n",
    "### Subsection 4\n",
    "\n",
    "Perhaps some exploration of the model selection (hyper-parameters) or algorithm selection task. Validation curves, plots showing the variability of perfromance across folds of the cross-validation, etc. If you're doing one, the outcome of the null hypothesis test or parsimony principle check to show how you are selecting the best model.\n",
    "\n",
    "### Subsection 5 \n",
    "\n",
    "Maybe you do model selection again, but using a different kind of metric than before?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "### Interpreting the result\n",
    "\n",
    "OK, you've given us quite a bit of tech informaiton above, now its time to tell us what to pay attention to in all that.  Think clearly about your results, decide on one main point and 2-4 secondary points you want us to understand. Highlight HOW your results support those points.  You probably want 2-5 sentences per point.\n",
    "\n",
    "### Limitations\n",
    "\n",
    "Are there any problems with the work?  For instance would more data change the nature of the problem? Would it be good to explore more hyperparams than you had time for?   \n",
    "\n",
    "### Ethics & Privacy\n",
    "\n",
    "If your project has obvious potential concerns with ethics or data privacy discuss that here.  Almost every ML project put into production can have ethical implications if you use your imagination. Use your imagination.\n",
    "\n",
    "Even if you can't come up with an obvious ethical concern that should be addressed, you should know that a large number of ML projects that go into producation have unintended consequences and ethical problems once in production. How will your team address these issues?\n",
    "\n",
    "Consider a tool to help you address the potential issues such as https://deon.drivendata.org\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Reiterate your main point and in just a few sentences tell us how your results support it. Mention how this work would fit in the background/context of other work in this field if you can. Suggest directions for future work if you want to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"lorenznote\"></a>1.[^](#lorenz): Lorenz, T. (9 Dec 2021) Birds Arenâ€™t Real, or Are They? Inside a Gen Z Conspiracy Theory. *The New York Times*. https://www.nytimes.com/2021/12/09/technology/birds-arent-real-gen-z-misinformation.html<br> \n",
    "<a name=\"admonishnote\"></a>2.[^](#admonish): Also refs should be important to the background, not some randomly chosen vaguely related stuff. Include a web link if possible in refs as above.<br>\n",
    "<a name=\"sotanote\"></a>3.[^](#sota): Perhaps the current state of the art solution such as you see on [Papers with code](https://paperswithcode.com/sota). Or maybe not SOTA, but rather a standard textbook/Kaggle solution to this kind of problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
